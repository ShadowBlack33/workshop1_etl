# Workshop-1 Â· ETL â†’ Data Warehouse (Star Schema) â†’ KPIs & Charts

[![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB)](https://www.python.org/)
[![pandas](https://img.shields.io/badge/pandas-2.x-150458)](https://pandas.pydata.org/)
[![matplotlib](https://img.shields.io/badge/matplotlib-3.x-11557c)](https://matplotlib.org/)
[![Rich](https://img.shields.io/badge/Rich-Console_Formatting-3fb950)](https://github.com/Textualize/rich)

Individual **ETL project in Python** that builds a **Data Warehouse (SQLite)** using a **star schema** from a candidates dataset, then computes **KPIs** and generates **charts (PNG only)**.

> **Important:** *All metrics and charts are computed from the Data Warehouse only.*  
> The CSV is used **only** to populate the DW (as a RAW staging table).

---

## ğŸ§­ Table of Contents
- [Goal](#goal)
- [Preview](#preview)
- [Features](#features)
- [Architecture](#architecture)
- [Star Schema â€“ Design Rationale](#star-schema--design-rationale)
- [Repository Structure](#repository-structure)
- [Requirements](#requirements)
- [Install & Run](#install--run)
- [KPIs](#kpis)
- [SQL Reference](#sql-reference)
- [Troubleshooting](#troubleshooting)
- [License](#license)

---

## ğŸ¯ Goal
- Implement a clear **ETL pipeline** (Extract â†’ Transform â†’ Load).
- Persist both **RAW** and **CLEAN** stages **inside** the DW.
- Model a **star schema** (dimensions + fact).
- Compute **hiring KPIs** and generate **PNG charts**.

---

## ğŸ–¼ï¸ Preview

<p align="center">
  <img src="visuals/contrataciones_tecnologia.png" alt="Hires by Technology (Top 10)" width="48%" />
  <img src="visuals/contrataciones_anio.png" alt="Hires by Year" width="48%" />
</p>
<p align="center">
  <img src="visuals/contrataciones_seniority.png" alt="Hires by Seniority" width="48%" />
  <img src="visuals/contrataciones_pais_anio.png" alt="Hires by Country per Year" width="48%" />
</p>

> The `visuals/` folder is generated by `main.py` and contains all PNG charts.

---

## âœ¨ Features
- **DW-driven analytics:** KPIs/charts query **SQLite** (not the CSV).
- **RAW staging** in DW: exact CSV snapshot â†’ `RawCandidates`.
- **CLEAN** in DW: normalized/typed dataset â†’ `CleanCandidates`.
- **Star schema** in DW: `Dim*` + `FactHires`.
- **Console KPIs** with **Rich**.
- **PNG charts** with **Matplotlib** â†’ `visuals/`.

---

## ğŸ—ï¸ Architecture

### Data Flow
```mermaid
flowchart LR
  A["CSV: data/candidates.csv"];
  B["RawCandidates (DW)"];
  C["CleanCandidates (DW)"];
  D["DimCandidate"];
  E["DimTechnology"];
  F["DimCountry"];
  G["DimDate"];
  H["FactHires"];
  I["KPIs (SQL)"];
  J["Charts (PNG)"];

  A -->|Extract| B;
  B -->|Transform| C;
  C --> D;
  C --> E;
  C --> F;
  C --> G;
  D --> H;
  E --> H;
  F --> H;
  G --> H;
  H --> I;
  H --> J;
````

### Star Schema (ER)

```mermaid
erDiagram
  DIMCANDIDATE ||--o{ FACTHIRES : candidate_id
  DIMTECHNOLOGY ||--o{ FACTHIRES : technology_id
  DIMCOUNTRY ||--o{ FACTHIRES : country_id
  DIMDATE ||--o{ FACTHIRES : date_id

  DIMCANDIDATE {
    int    candidate_id PK
    string first_name
    string last_name
    string email
    string seniority
    int    yoe
  }

  DIMTECHNOLOGY {
    int    technology_id PK
    string technology
  }

  DIMCOUNTRY {
    int    country_id PK
    string country
  }

  DIMDATE {
    int    date_id PK
    string full_date
    int    year
    int    month
    int    day
  }

  FACTHIRES {
    int   fact_id PK
    int   candidate_id FK
    int   technology_id FK
    int   country_id FK
    int   date_id FK
    float code_challenge_score
    float technical_interview_score
    int   hired
  }
```

---

## Star Schema â€“ Design Rationale

* **Fact grain:** one row per application (candidate Ã— application date) with `code_challenge_score`, `technical_interview_score`, and `hired`.
* **Dimensions:**

  * `DimCandidate` â€” attributes for segmentation (seniority, `yoe`), stable identifiers (`email`).
  * `DimTechnology` â€” technology associated to the process.
  * `DimCountry` â€” geographic breakdown and focus countries.
  * `DimDate` â€” standardized calendar cuts (year/month/day).
* **Why this works:** directly answers KPIs (by tech/year/seniority/country) and supports derived metrics (hire rate, averages) with simple, efficient SQL.

---

## ğŸ“ Repository Structure

```
workshop1_etl/
â”œâ”€ data/
â”‚  â””â”€ candidates.csv          # (NOT committed) â€” only to populate the DW
â”œâ”€ dw/
â”‚  â””â”€ workshop1_dw.sqlite     # (generated) â€” the SQLite DW
â”œâ”€ sql/
â”‚  â””â”€ queries.sql             # KPI queries (reference)
â”œâ”€ src/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ extract.py              # CSV â†’ DataFrame
â”‚  â”œâ”€ transform.py            # normalize/derive â†’ CLEAN schema
â”‚  â””â”€ load.py                 # RAW/CLEAN/STAR loaders (SQLite)
â”œâ”€ visuals/                   # PNG charts (Matplotlib)
â”œâ”€ main.py                    # Orchestrates: CSVâ†’RAWâ†’CLEANâ†’STAR â†’ KPIs/PNG
â”œâ”€ requirements.txt
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âœ… Requirements

* **Python 3.10+**
* Install:

  ```bash
  pip install -r requirements.txt
  ```

  Uses: `pandas`, `matplotlib`, `rich`

---

## âš™ï¸ Install & Run

```bash
# optional venv
python -m venv .venv
# Windows: .venv\Scripts\Activate.ps1
# macOS/Linux: source .venv/bin/activate

pip install -r requirements.txt

# place semicolon-separated CSV:
#   data/candidates.csv
python main.py
```

Outputs:

* DW at `dw/workshop1_dw.sqlite`
* KPIs (console, via Rich)
* PNG charts in `visuals/`

> CSV schema and details: see `data/README.md`.

---

## ğŸ“Š KPIs

All KPIs are computed from **FactHires** joined with dimensions:

1. **Hires by technology** â€” Hires, Total, Rate %
2. **Hires by year** â€” Hires, Total, Rate %
3. **Hires by seniority** â€” Hires, Total, Rate %
4. **Hires by country (per year)** â€” Trend for US/Brazil/Colombia/Ecuador
5. **Hiring rate by country (%)** â€” Country ranking
6. **Average scores (Hired vs Not)** â€” Code Challenge & Interview

---

## ğŸ§¾ SQL Reference

See `sql/queries.sql` for the exact SQL used for the KPIs.

---

## ğŸ› ï¸ Troubleshooting

* CSV delimiter **must be `;`** and encoding **UTF-8**.
* Dates **YYYY-MM-DD**.
* Windows line-endings notice (`LF â†’ CRLF`): harmless.
* `sqlite3.OperationalError: database is locked` â†’ close any app using the `.sqlite` and rerun.
* If you changed CSV headers, the pipeline automatically normalizes them; ensure the CSV has at least: first/last name, email, seniority, `yoe`, technology, country, application date, code/interview scores.

---

## ğŸ“œ License

MIT Â© 2025 â€” ShadowBlack33